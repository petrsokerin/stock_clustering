{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "233798fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from autoencoders import Conv1dAutoEncoder, LSTMAutoEncoder, TickerDataModule, MLPAutoEncoder\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from math import floor\n",
    "import torch\n",
    "\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c6a81ab8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\artem\\anaconda3\\envs\\ml\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:62: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    }
   ],
   "source": [
    "model_mlp = MLPAutoEncoder.load_from_checkpoint('autoencoders/lightning_logs/version_3/checkpoints/epoch=149-step=105599.ckpt',\n",
    "                                            in_features=30,\n",
    "                                            latent_features=8)\n",
    "model_lstm = LSTMAutoEncoder.load_from_checkpoint('autoencoders/lightning_logs/version_1/checkpoints/epoch=29-step=99329.ckpt',\n",
    "                                            seq_len=100,\n",
    "                                            n_features=1)\n",
    "model_cae = Conv1dAutoEncoder.load_from_checkpoint('autoencoders/lightning_logs/version_2/checkpoints/epoch=99-step=70399.ckpt',\n",
    "                                            in_channels=1,\n",
    "                                            n_latent_features=1)\n",
    "model_mlp.eval()\n",
    "model_lstm.eval()\n",
    "model_cae.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d12d5654",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/ticker_data_Close.csv', index_col=[0]).dropna(axis=1).pct_change().fillna(0).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "84c9a1ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_30 = df.values[100, 100:190]\n",
    "test_30 = torch.tensor(test_30.reshape(3, 1, 30)).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "43c839ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 18])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = model_cae.predict_step(test_30)\n",
    "test.squeeze_()\n",
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "5cbe6df2",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = test.detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "63362d04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.3172268 , -0.20717724,  1.2663149 ,  1.2335238 ,  0.87040025,\n",
       "        2.497875  ,  1.4231535 , -0.36850038, -3.012929  ,  0.344663  ,\n",
       "        0.3438032 ,  0.28385302,  0.33017513, -0.5936204 ,  0.30444106,\n",
       "       -1.093338  , -1.1015083 , -0.6877598 ], dtype=float32)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e95f2b90",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\artem\\anaconda3\\envs\\ml\\lib\\site-packages\\torch\\nn\\modules\\loss.py:520: UserWarning: Using a target size (torch.Size([3, 30])) that is different to the input size (torch.Size([3, 1, 30])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(0.0005, grad_fn=<MseLossBackward0>)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.nn.MSELoss()(test_30, model_mlp(test_30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "de7d7198",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83f117d1fe7848828a05c214d5dd1624",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mlp_encoded = np.zeros((df.shape[0], 8))\n",
    "lstm_encoded = np.zeros((df.shape[0], 16))\n",
    "cae_encoded = np.zeros((df.shape[0], 18))\n",
    "\n",
    "for i, name_ticker in tqdm(enumerate(np.unique(df.index))):\n",
    "    ts_name = df[df.index == name_ticker].values\n",
    "    ts_name = ts_name.flatten()\n",
    "    seq_len = ts_name.shape[0]\n",
    "    fl_1 = floor(seq_len / 30)\n",
    "    sample_1 = ts_name[:30 * fl_1].reshape(fl_1, 1, 30)\n",
    "    fl_2 = floor(seq_len / 100)\n",
    "    sample_2 = ts_name[:100 * fl_2].reshape(fl_2, 1, 100)\n",
    "    \n",
    "    mlp_sample = model_mlp.predict_step(torch.tensor(sample_1).float()).detach().numpy()\n",
    "    cae_sample = model_cae.predict_step(torch.tensor(sample_1).float()).squeeze().detach().numpy()\n",
    "    # lstm_sample = model_lstm.predict_step(torch.tensor(sample_2).float()).detach().numpy()\n",
    "    \n",
    "    mlp_emb = mlp_sample.mean(axis=0)\n",
    "    cae_emb = cae_sample.mean(axis=0)\n",
    "    # lstm_emb = lstm_sample.mean(axis=0)\n",
    "    \n",
    "    mlp_encoded[i, :] = mlp_emb\n",
    "    cae_encoded[i, :] = cae_emb\n",
    "    # lstm_encoded[i, :] = lstm_emb\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "698c5077",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mlp = pd.DataFrame(mlp_encoded, index=np.unique(df.index))\n",
    "df_cae = pd.DataFrame(cae_encoded, index=np.unique(df.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "8cdc938c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>A</th>\n",
       "      <td>0.443793</td>\n",
       "      <td>-0.826058</td>\n",
       "      <td>0.599175</td>\n",
       "      <td>-0.146035</td>\n",
       "      <td>-0.087064</td>\n",
       "      <td>0.596984</td>\n",
       "      <td>-1.209998</td>\n",
       "      <td>1.210354</td>\n",
       "      <td>-0.572228</td>\n",
       "      <td>0.390400</td>\n",
       "      <td>0.657043</td>\n",
       "      <td>-0.250393</td>\n",
       "      <td>0.165594</td>\n",
       "      <td>0.196078</td>\n",
       "      <td>0.106130</td>\n",
       "      <td>-0.187778</td>\n",
       "      <td>-0.727875</td>\n",
       "      <td>-0.005228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AAL</th>\n",
       "      <td>1.709430</td>\n",
       "      <td>-0.947921</td>\n",
       "      <td>2.526441</td>\n",
       "      <td>0.243858</td>\n",
       "      <td>-0.631920</td>\n",
       "      <td>-1.918355</td>\n",
       "      <td>1.711012</td>\n",
       "      <td>-0.177325</td>\n",
       "      <td>-0.589335</td>\n",
       "      <td>-0.269961</td>\n",
       "      <td>-0.765850</td>\n",
       "      <td>-0.712869</td>\n",
       "      <td>1.710327</td>\n",
       "      <td>-0.655665</td>\n",
       "      <td>0.017455</td>\n",
       "      <td>-0.286342</td>\n",
       "      <td>-1.116661</td>\n",
       "      <td>-0.227533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AAP</th>\n",
       "      <td>0.531765</td>\n",
       "      <td>-0.373268</td>\n",
       "      <td>0.972495</td>\n",
       "      <td>-0.575971</td>\n",
       "      <td>-0.108009</td>\n",
       "      <td>0.513265</td>\n",
       "      <td>-0.587028</td>\n",
       "      <td>-0.394587</td>\n",
       "      <td>-0.174555</td>\n",
       "      <td>0.577220</td>\n",
       "      <td>-0.370121</td>\n",
       "      <td>1.688423</td>\n",
       "      <td>-0.640823</td>\n",
       "      <td>-0.329382</td>\n",
       "      <td>0.450803</td>\n",
       "      <td>0.078640</td>\n",
       "      <td>-0.374888</td>\n",
       "      <td>-0.426519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AAPL</th>\n",
       "      <td>0.533724</td>\n",
       "      <td>-0.879952</td>\n",
       "      <td>0.658384</td>\n",
       "      <td>-0.103453</td>\n",
       "      <td>0.235794</td>\n",
       "      <td>0.351935</td>\n",
       "      <td>-1.135496</td>\n",
       "      <td>0.392409</td>\n",
       "      <td>-0.322289</td>\n",
       "      <td>0.503350</td>\n",
       "      <td>0.115770</td>\n",
       "      <td>0.361362</td>\n",
       "      <td>1.122436</td>\n",
       "      <td>-0.464904</td>\n",
       "      <td>0.492655</td>\n",
       "      <td>0.103350</td>\n",
       "      <td>-0.517387</td>\n",
       "      <td>0.514078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ABBV</th>\n",
       "      <td>0.934724</td>\n",
       "      <td>-1.180916</td>\n",
       "      <td>1.008926</td>\n",
       "      <td>0.096233</td>\n",
       "      <td>-1.175642</td>\n",
       "      <td>1.229719</td>\n",
       "      <td>-0.286264</td>\n",
       "      <td>0.017199</td>\n",
       "      <td>-0.905562</td>\n",
       "      <td>0.797326</td>\n",
       "      <td>0.513067</td>\n",
       "      <td>0.165163</td>\n",
       "      <td>0.069634</td>\n",
       "      <td>-0.484828</td>\n",
       "      <td>0.714872</td>\n",
       "      <td>-0.424400</td>\n",
       "      <td>-0.643833</td>\n",
       "      <td>0.022571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>YUM</th>\n",
       "      <td>0.718343</td>\n",
       "      <td>-0.658262</td>\n",
       "      <td>1.194584</td>\n",
       "      <td>-0.642399</td>\n",
       "      <td>0.005455</td>\n",
       "      <td>0.116641</td>\n",
       "      <td>-0.140065</td>\n",
       "      <td>-0.537059</td>\n",
       "      <td>-0.446104</td>\n",
       "      <td>0.472845</td>\n",
       "      <td>-0.356646</td>\n",
       "      <td>-0.069050</td>\n",
       "      <td>0.603238</td>\n",
       "      <td>-0.075377</td>\n",
       "      <td>0.308628</td>\n",
       "      <td>-0.744750</td>\n",
       "      <td>-0.391983</td>\n",
       "      <td>0.078181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ZBH</th>\n",
       "      <td>0.562346</td>\n",
       "      <td>-1.051160</td>\n",
       "      <td>0.880200</td>\n",
       "      <td>-0.299489</td>\n",
       "      <td>0.112429</td>\n",
       "      <td>0.122190</td>\n",
       "      <td>-0.408987</td>\n",
       "      <td>-0.414950</td>\n",
       "      <td>-0.562356</td>\n",
       "      <td>0.634573</td>\n",
       "      <td>0.302692</td>\n",
       "      <td>-0.210985</td>\n",
       "      <td>0.156019</td>\n",
       "      <td>0.486356</td>\n",
       "      <td>0.034402</td>\n",
       "      <td>-0.913391</td>\n",
       "      <td>-0.265685</td>\n",
       "      <td>-0.076005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ZBRA</th>\n",
       "      <td>1.670885</td>\n",
       "      <td>-1.166043</td>\n",
       "      <td>1.560517</td>\n",
       "      <td>0.246390</td>\n",
       "      <td>-0.331013</td>\n",
       "      <td>0.732850</td>\n",
       "      <td>-0.610915</td>\n",
       "      <td>0.408119</td>\n",
       "      <td>-0.922116</td>\n",
       "      <td>0.753443</td>\n",
       "      <td>0.152267</td>\n",
       "      <td>0.206921</td>\n",
       "      <td>-0.235822</td>\n",
       "      <td>-0.294588</td>\n",
       "      <td>0.617337</td>\n",
       "      <td>-1.109380</td>\n",
       "      <td>-0.318570</td>\n",
       "      <td>-0.065585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ZION</th>\n",
       "      <td>0.621853</td>\n",
       "      <td>-0.208176</td>\n",
       "      <td>0.932140</td>\n",
       "      <td>-0.203061</td>\n",
       "      <td>-0.261352</td>\n",
       "      <td>0.651772</td>\n",
       "      <td>-0.799211</td>\n",
       "      <td>0.667269</td>\n",
       "      <td>-0.145326</td>\n",
       "      <td>0.345101</td>\n",
       "      <td>-0.218045</td>\n",
       "      <td>-0.138021</td>\n",
       "      <td>0.217204</td>\n",
       "      <td>-0.608566</td>\n",
       "      <td>0.373601</td>\n",
       "      <td>-0.063144</td>\n",
       "      <td>-1.158349</td>\n",
       "      <td>-0.223093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ZTS</th>\n",
       "      <td>0.739854</td>\n",
       "      <td>-0.512587</td>\n",
       "      <td>0.590606</td>\n",
       "      <td>0.016202</td>\n",
       "      <td>0.044402</td>\n",
       "      <td>0.517670</td>\n",
       "      <td>-1.040878</td>\n",
       "      <td>0.082111</td>\n",
       "      <td>-0.047703</td>\n",
       "      <td>0.432725</td>\n",
       "      <td>-0.291558</td>\n",
       "      <td>0.192763</td>\n",
       "      <td>0.296448</td>\n",
       "      <td>-0.196463</td>\n",
       "      <td>0.659601</td>\n",
       "      <td>-0.429377</td>\n",
       "      <td>-0.321716</td>\n",
       "      <td>0.340392</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>487 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1         2         3         4         5         6   \\\n",
       "A     0.443793 -0.826058  0.599175 -0.146035 -0.087064  0.596984 -1.209998   \n",
       "AAL   1.709430 -0.947921  2.526441  0.243858 -0.631920 -1.918355  1.711012   \n",
       "AAP   0.531765 -0.373268  0.972495 -0.575971 -0.108009  0.513265 -0.587028   \n",
       "AAPL  0.533724 -0.879952  0.658384 -0.103453  0.235794  0.351935 -1.135496   \n",
       "ABBV  0.934724 -1.180916  1.008926  0.096233 -1.175642  1.229719 -0.286264   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "YUM   0.718343 -0.658262  1.194584 -0.642399  0.005455  0.116641 -0.140065   \n",
       "ZBH   0.562346 -1.051160  0.880200 -0.299489  0.112429  0.122190 -0.408987   \n",
       "ZBRA  1.670885 -1.166043  1.560517  0.246390 -0.331013  0.732850 -0.610915   \n",
       "ZION  0.621853 -0.208176  0.932140 -0.203061 -0.261352  0.651772 -0.799211   \n",
       "ZTS   0.739854 -0.512587  0.590606  0.016202  0.044402  0.517670 -1.040878   \n",
       "\n",
       "            7         8         9         10        11        12        13  \\\n",
       "A     1.210354 -0.572228  0.390400  0.657043 -0.250393  0.165594  0.196078   \n",
       "AAL  -0.177325 -0.589335 -0.269961 -0.765850 -0.712869  1.710327 -0.655665   \n",
       "AAP  -0.394587 -0.174555  0.577220 -0.370121  1.688423 -0.640823 -0.329382   \n",
       "AAPL  0.392409 -0.322289  0.503350  0.115770  0.361362  1.122436 -0.464904   \n",
       "ABBV  0.017199 -0.905562  0.797326  0.513067  0.165163  0.069634 -0.484828   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "YUM  -0.537059 -0.446104  0.472845 -0.356646 -0.069050  0.603238 -0.075377   \n",
       "ZBH  -0.414950 -0.562356  0.634573  0.302692 -0.210985  0.156019  0.486356   \n",
       "ZBRA  0.408119 -0.922116  0.753443  0.152267  0.206921 -0.235822 -0.294588   \n",
       "ZION  0.667269 -0.145326  0.345101 -0.218045 -0.138021  0.217204 -0.608566   \n",
       "ZTS   0.082111 -0.047703  0.432725 -0.291558  0.192763  0.296448 -0.196463   \n",
       "\n",
       "            14        15        16        17  \n",
       "A     0.106130 -0.187778 -0.727875 -0.005228  \n",
       "AAL   0.017455 -0.286342 -1.116661 -0.227533  \n",
       "AAP   0.450803  0.078640 -0.374888 -0.426519  \n",
       "AAPL  0.492655  0.103350 -0.517387  0.514078  \n",
       "ABBV  0.714872 -0.424400 -0.643833  0.022571  \n",
       "...        ...       ...       ...       ...  \n",
       "YUM   0.308628 -0.744750 -0.391983  0.078181  \n",
       "ZBH   0.034402 -0.913391 -0.265685 -0.076005  \n",
       "ZBRA  0.617337 -1.109380 -0.318570 -0.065585  \n",
       "ZION  0.373601 -0.063144 -1.158349 -0.223093  \n",
       "ZTS   0.659601 -0.429377 -0.321716  0.340392  \n",
       "\n",
       "[487 rows x 18 columns]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_mlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d68e93b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
