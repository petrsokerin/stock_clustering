{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "db517c9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from autoencoders import Conv1dAutoEncoder, LSTMAutoEncoder, TickerDataModule, MLPAutoEncoder\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from math import floor\n",
    "import torch\n",
    "\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eed8619f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\artem\\anaconda3\\envs\\ml\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:62: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    }
   ],
   "source": [
    "model_mlp = MLPAutoEncoder.load_from_checkpoint('autoencoders/lightning_logs/version_3/checkpoints/epoch=149-step=105599.ckpt',\n",
    "                                            in_features=30,\n",
    "                                            latent_features=8)\n",
    "model_lstm = LSTMAutoEncoder.load_from_checkpoint('autoencoders/lightning_logs/version_1/checkpoints/epoch=29-step=99329.ckpt',\n",
    "                                            seq_len=100,\n",
    "                                            n_features=1)\n",
    "model_cae = Conv1dAutoEncoder.load_from_checkpoint('autoencoders/lightning_logs/version_2/checkpoints/epoch=99-step=70399.ckpt',\n",
    "                                            in_channels=1,\n",
    "                                            n_latent_features=1)\n",
    "model_mlp.eval()\n",
    "model_lstm.eval()\n",
    "model_cae.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "adb4b25b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/ticker_data_Close.csv', index_col=[0]).dropna(axis=1).pct_change().fillna(0).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "4e34142a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_30 = df.values[100, 100:190]\n",
    "test_30 = torch.tensor(test_30.reshape(3, 1, 30)).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "cdf710a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 18])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = model_cae.predict_step(test_30)\n",
    "test.squeeze_()\n",
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "07214884",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = test.detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "11cbb8cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.3172268 , -0.20717724,  1.2663149 ,  1.2335238 ,  0.87040025,\n",
       "        2.497875  ,  1.4231535 , -0.36850038, -3.012929  ,  0.344663  ,\n",
       "        0.3438032 ,  0.28385302,  0.33017513, -0.5936204 ,  0.30444106,\n",
       "       -1.093338  , -1.1015083 , -0.6877598 ], dtype=float32)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "8d6ba351",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\artem\\anaconda3\\envs\\ml\\lib\\site-packages\\torch\\nn\\modules\\loss.py:520: UserWarning: Using a target size (torch.Size([3, 30])) that is different to the input size (torch.Size([3, 1, 30])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(0.0005, grad_fn=<MseLossBackward0>)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.nn.MSELoss()(test_30, model_mlp(test_30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "872f865a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83f117d1fe7848828a05c214d5dd1624",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mlp_encoded = np.zeros((df.shape[0], 8))\n",
    "lstm_encoded = np.zeros((df.shape[0], 16))\n",
    "cae_encoded = np.zeros((df.shape[0], 18))\n",
    "\n",
    "for i, name_ticker in tqdm(enumerate(np.unique(df.index))):\n",
    "    ts_name = df[df.index == name_ticker].values\n",
    "    ts_name = ts_name.flatten()\n",
    "    seq_len = ts_name.shape[0]\n",
    "    fl_1 = floor(seq_len / 30)\n",
    "    sample_1 = ts_name[:30 * fl_1].reshape(fl_1, 1, 30)\n",
    "    fl_2 = floor(seq_len / 100)\n",
    "    sample_2 = ts_name[:100 * fl_2].reshape(fl_2, 1, 100)\n",
    "    \n",
    "    mlp_sample = model_mlp.predict_step(torch.tensor(sample_1).float()).detach().numpy()\n",
    "    cae_sample = model_cae.predict_step(torch.tensor(sample_1).float()).squeeze().detach().numpy()\n",
    "    # lstm_sample = model_lstm.predict_step(torch.tensor(sample_2).float()).detach().numpy()\n",
    "    \n",
    "    mlp_emb = mlp_sample.mean(axis=0)\n",
    "    cae_emb = cae_sample.mean(axis=0)\n",
    "    # lstm_emb = lstm_sample.mean(axis=0)\n",
    "    \n",
    "    mlp_encoded[i, :] = mlp_emb\n",
    "    cae_encoded[i, :] = cae_emb\n",
    "    # lstm_encoded[i, :] = lstm_emb\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "69926901",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mlp = pd.DataFrame(mlp_encoded, index=np.unique(df.index))\n",
    "df_cae = pd.DataFrame(cae_encoded, index=np.unique(df.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "79951b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mlp.to_csv('data/nn_data/ticker_data_mlp.csv')\n",
    "df_cae.to_csv('data/nn_data/ticker_data_cae.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "737c24b1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
